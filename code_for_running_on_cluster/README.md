# Code for running an array job on a cluster

## General
In this folder you can find the code you need to run a batch of simulations as an array job on a Grid Engine computer cluster (works on the Open Grid Scheduler batch system on Scientific Linux 7 at least). The example allows you to create an array job on a cluster which runs the same simulation (2 independent runs of a single learner learning from a single speaker for 60 observations) but looping through each of the possible speaker lexicons (for a lexicon with 3 meanings and 3 signals in this case; 343 possible lexicons in total).

## Usage Instructions
In order to run this array job on a cluster, upload the files in this folder *and* all the core modules in the folder [python_code](https://github.com/marieke-woensdregt/model_coevolution_language_mindreading/tree/master/python_code) (i.e. all the python files *without* the prefix `run_` or `unpickle_`), and submit the job with the command `qsub eddie_run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_60_C_2_R.sh`
The code in this folder is meant for doing a quick test run with only 60 observations per learner and only 2 independent simulation runs. You can change these parameters in the parameter settings block at the top of the python script [run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_60_C_2_R.py](https://github.com/marieke-woensdregt/model_coevolution_language_mindreading/blob/master/code_for_running_on_cluster/run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_60_C_2_R.py). (e.g. change `n_contexts = 60` to `n_contexts = 600` and `n_runs = 2` to `n_runs = 200`). 
**NOTE** if you want to run a longer simulation than the one in this example, you'll also have to change the runtime limit in the `.sh` file (which is currently set to 1 hour) by changing the parameter `#$ -l h_rt=01:00:00` to e.g. `#$ -l h_rt=15:00:00`. A simulation of a literal learner learning from a literal speaker (as in this example code) with 600 observations per learner and 200 separate runs should take about 6 hours to run, but make sure you leave a reasonable amount of buffer in case it takes a bit longer. For some simulations you might also have to increase the memory limit (currently set to 2 GB) by changing the line `#$ -l h_vmem=2G` in the `.sh` script.


## Navigating the code
Both the python scripts and the .sh scripts in this folder contain comments and docstrings explaining what each line or function does. I also used long and intelligible variable and function names, which should hopefully make the code relatively easy to read.
